{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17c7a36-f8d3-4647-b380-fc24cddc0616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded lazy data:  dask.array<from-zarr, shape=(1, 1, 464, 1280, 928), dtype=uint16, chunksize=(1, 1, 128, 128, 128), chunktype=numpy.ndarray>\n",
      "Estimating super chunksize. Provided super chunksize: None - Target MB: 2048\n",
      "Estimated chunksize to fit in memory 2048 MiB: (464, 1280, 928)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading path from /data/best_model_097_2d.ckpt\n",
      "Total batches:  116.0 (464, 1280, 928)\n"
     ]
    }
   ],
   "source": [
    "from aind_large_scale_prediction.generator.utils import (\n",
    "    concatenate_lazy_data, recover_global_position, unpad_global_coords)\n",
    "from aind_large_scale_prediction.io import ImageReaderFactory\n",
    "from aind_large_scale_prediction.generator.dataset import create_data_loader\n",
    "import numpy as np\n",
    "import logging\n",
    "from aind_brain_segmentation.model.network import Neuratt\n",
    "import multiprocessing\n",
    "\n",
    "target_size_mb = 2048\n",
    "n_workers = 0\n",
    "super_chunksize = None#(200, 1024, 928)\n",
    "scale = 3\n",
    "smartspim_id = \"782646\"\n",
    "image_path = \"s3://aind-open-data/SmartSPIM_782646_2025-02-21_16-55-46_stitched_2025-03-06_08-22-36/image_tile_fusing/OMEZarr/Ex_639_Em_667.zarr\"\n",
    "#\"s3://aind-open-data/SmartSPIM_780343_2025-02-18_12-34-40_stitched_2025-02-25_08-15-10/image_tile_fusing/OMEZarr/Ex_639_Em_667.zarr\"\n",
    "# \"s3://aind-open-data/SmartSPIM_782746_2025-02-10_15-15-28_stitched_2025-02-25_08-50-23/image_tile_fusing/OMEZarr/Ex_639_Em_667.zarr\"\n",
    "# \"s3://aind-open-data/SmartSPIM_782744_2025-02-10_10-02-32_stitched_2025-02-25_09-53-12/image_tile_fusing/OMEZarr/Ex_639_Em_667.zarr\"\n",
    "# \"s3://aind-open-data/SmartSPIM_780343_2025-02-18_12-34-40_stitched_2025-02-25_08-15-10/image_tile_fusing/OMEZarr/Ex_639_Em_667.zarr\"\n",
    "#'s3://aind-open-data/SmartSPIM_729674_2024-12-16_12-16-28_stitched_2024-12-18_07-35-30/image_tile_fusing/OMEZarr/Ex_639_Em_680.zarr'\n",
    "#'s3://aind-open-data/SmartSPIM_761339_2025-01-10_21-19-15_stitched_2025-01-12_05-39-33/image_tile_fusing/OMEZarr/Ex_488_Em_525.zarr'\n",
    "checkpoint_path = \"/data/best_model_097_2d.ckpt\"\n",
    "#\"/results/whole_brain_seg/whole_brain_seg/cymgslil/checkpoints/best_model.ckpt\"\n",
    "\n",
    "# \"/scratch/latest_best_model_smartspim_clamp_int.ckpt\"\n",
    "#\"/data/smartspim_brain_seg_models/whole_brain_seg/whole_brain_seg/cfelpja3/checkpoints/best_model.ckpt\"\n",
    "\n",
    "device = None\n",
    "\n",
    "pin_memory = True\n",
    "if device is not None:\n",
    "    pin_memory = False\n",
    "    multiprocessing.set_start_method(\"spawn\", force=True)\n",
    "    \n",
    "axis_pad = 0\n",
    "overlap_prediction_chunksize = (axis_pad, axis_pad, axis_pad)\n",
    "\n",
    "lazy_data = (\n",
    "    ImageReaderFactory()\n",
    "    .create(data_path=str(image_path), parse_path=False, multiscale=scale)\n",
    "    .as_dask_array()\n",
    ")\n",
    "\n",
    "prediction_chunksize = (4, lazy_data.shape[-2], lazy_data.shape[-1])\n",
    "\n",
    "logger = logging.Logger(name=\"log\")\n",
    "\n",
    "print(\"Loaded lazy data: \", lazy_data)\n",
    "batch_size = 1\n",
    "dtype = np.float32\n",
    "zarr_data_loader, zarr_dataset = create_data_loader(\n",
    "    lazy_data=lazy_data,\n",
    "    target_size_mb=target_size_mb,\n",
    "    prediction_chunksize=prediction_chunksize,\n",
    "    overlap_prediction_chunksize=overlap_prediction_chunksize,\n",
    "    n_workers=n_workers,\n",
    "    batch_size=batch_size,\n",
    "    dtype=dtype,  # Allowed data type to process with pytorch cuda\n",
    "    super_chunksize=super_chunksize,\n",
    "    lazy_callback_fn=None,  # partial_lazy_deskewing,\n",
    "    logger=logger,\n",
    "    device=device,\n",
    "    pin_memory=pin_memory,\n",
    "    override_suggested_cpus=False,\n",
    "    drop_last=True,\n",
    "    locked_array=False,\n",
    ")\n",
    "\n",
    "# Creating model\n",
    "segmentation_model = Neuratt()\n",
    "\n",
    "if checkpoint_path:\n",
    "    print(f\"Loading path from {checkpoint_path}\")\n",
    "    segmentation_model = Neuratt.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "total_batches = sum(zarr_dataset.internal_slice_sum) / batch_size\n",
    "print(\"Total batches: \", total_batches, zarr_dataset.lazy_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "294a0fa7-5fd2-4f23-87bf-0c51dc6efc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 1.03 GiB </td>\n",
       "                        <td> 4.00 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1, 464, 1280, 928) </td>\n",
       "                        <td> (1, 1, 128, 128, 128) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 320 chunks in 2 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"352\" height=\"195\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1</text>\n",
       "  <text x=\"45.412617\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,45.412617,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"95\" y1=\"12\" x2=\"120\" y2=\"37\" />\n",
       "  <line x1=\"95\" y1=\"24\" x2=\"120\" y2=\"49\" />\n",
       "  <line x1=\"95\" y1=\"36\" x2=\"120\" y2=\"61\" />\n",
       "  <line x1=\"95\" y1=\"48\" x2=\"120\" y2=\"73\" />\n",
       "  <line x1=\"95\" y1=\"60\" x2=\"120\" y2=\"85\" />\n",
       "  <line x1=\"95\" y1=\"72\" x2=\"120\" y2=\"97\" />\n",
       "  <line x1=\"95\" y1=\"84\" x2=\"120\" y2=\"109\" />\n",
       "  <line x1=\"95\" y1=\"96\" x2=\"120\" y2=\"121\" />\n",
       "  <line x1=\"95\" y1=\"108\" x2=\"120\" y2=\"133\" />\n",
       "  <line x1=\"95\" y1=\"120\" x2=\"120\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"95\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"102\" y1=\"7\" x2=\"102\" y2=\"127\" />\n",
       "  <line x1=\"109\" y1=\"14\" x2=\"109\" y2=\"134\" />\n",
       "  <line x1=\"116\" y1=\"21\" x2=\"116\" y2=\"141\" />\n",
       "  <line x1=\"120\" y1=\"25\" x2=\"120\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 120.96521372150383,25.965213721503837 120.96521372150383,145.96521372150383 95.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"182\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"102\" y1=\"7\" x2=\"189\" y2=\"7\" />\n",
       "  <line x1=\"109\" y1=\"14\" x2=\"196\" y2=\"14\" />\n",
       "  <line x1=\"116\" y1=\"21\" x2=\"203\" y2=\"21\" />\n",
       "  <line x1=\"120\" y1=\"25\" x2=\"207\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"107\" y1=\"0\" x2=\"132\" y2=\"25\" />\n",
       "  <line x1=\"119\" y1=\"0\" x2=\"144\" y2=\"25\" />\n",
       "  <line x1=\"131\" y1=\"0\" x2=\"156\" y2=\"25\" />\n",
       "  <line x1=\"143\" y1=\"0\" x2=\"168\" y2=\"25\" />\n",
       "  <line x1=\"155\" y1=\"0\" x2=\"180\" y2=\"25\" />\n",
       "  <line x1=\"167\" y1=\"0\" x2=\"192\" y2=\"25\" />\n",
       "  <line x1=\"179\" y1=\"0\" x2=\"204\" y2=\"25\" />\n",
       "  <line x1=\"182\" y1=\"0\" x2=\"207\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 182.0,0.0 207.96521372150383,25.965213721503837 120.96521372150383,25.965213721503837\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"120\" y1=\"25\" x2=\"207\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"37\" x2=\"207\" y2=\"37\" />\n",
       "  <line x1=\"120\" y1=\"49\" x2=\"207\" y2=\"49\" />\n",
       "  <line x1=\"120\" y1=\"61\" x2=\"207\" y2=\"61\" />\n",
       "  <line x1=\"120\" y1=\"73\" x2=\"207\" y2=\"73\" />\n",
       "  <line x1=\"120\" y1=\"85\" x2=\"207\" y2=\"85\" />\n",
       "  <line x1=\"120\" y1=\"97\" x2=\"207\" y2=\"97\" />\n",
       "  <line x1=\"120\" y1=\"109\" x2=\"207\" y2=\"109\" />\n",
       "  <line x1=\"120\" y1=\"121\" x2=\"207\" y2=\"121\" />\n",
       "  <line x1=\"120\" y1=\"133\" x2=\"207\" y2=\"133\" />\n",
       "  <line x1=\"120\" y1=\"145\" x2=\"207\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"120\" y1=\"25\" x2=\"120\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"132\" y1=\"25\" x2=\"132\" y2=\"145\" />\n",
       "  <line x1=\"144\" y1=\"25\" x2=\"144\" y2=\"145\" />\n",
       "  <line x1=\"156\" y1=\"25\" x2=\"156\" y2=\"145\" />\n",
       "  <line x1=\"168\" y1=\"25\" x2=\"168\" y2=\"145\" />\n",
       "  <line x1=\"180\" y1=\"25\" x2=\"180\" y2=\"145\" />\n",
       "  <line x1=\"192\" y1=\"25\" x2=\"192\" y2=\"145\" />\n",
       "  <line x1=\"204\" y1=\"25\" x2=\"204\" y2=\"145\" />\n",
       "  <line x1=\"207\" y1=\"25\" x2=\"207\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"120.96521372150383,25.965213721503837 207.96521372150383,25.965213721503837 207.96521372150383,145.96521372150383 120.96521372150383,145.96521372150383\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"164.465214\" y=\"165.965214\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >928</text>\n",
       "  <text x=\"227.965214\" y=\"85.965214\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,227.965214,85.965214)\">1280</text>\n",
       "  <text x=\"97.982607\" y=\"152.982607\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,97.982607,152.982607)\">464</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(1, 1, 464, 1280, 928), dtype=uint16, chunksize=(1, 1, 128, 128, 128), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac529b57-5194-47a1-a100-2c922b26f657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 2.05 GiB </td>\n",
       "                        <td> 8.00 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (464, 1280, 928) </td>\n",
       "                        <td> (128, 128, 128) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 320 chunks in 4 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"172\" height=\"195\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"12\" x2=\"35\" y2=\"37\" />\n",
       "  <line x1=\"10\" y1=\"24\" x2=\"35\" y2=\"49\" />\n",
       "  <line x1=\"10\" y1=\"36\" x2=\"35\" y2=\"61\" />\n",
       "  <line x1=\"10\" y1=\"48\" x2=\"35\" y2=\"73\" />\n",
       "  <line x1=\"10\" y1=\"60\" x2=\"35\" y2=\"85\" />\n",
       "  <line x1=\"10\" y1=\"72\" x2=\"35\" y2=\"97\" />\n",
       "  <line x1=\"10\" y1=\"84\" x2=\"35\" y2=\"109\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"35\" y2=\"121\" />\n",
       "  <line x1=\"10\" y1=\"108\" x2=\"35\" y2=\"133\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"35\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"127\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"134\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"141\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.96521372150384,25.965213721503837 35.96521372150384,145.96521372150383 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"97\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"104\" y2=\"7\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"111\" y2=\"14\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"118\" y2=\"21\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"122\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"47\" y2=\"25\" />\n",
       "  <line x1=\"34\" y1=\"0\" x2=\"59\" y2=\"25\" />\n",
       "  <line x1=\"46\" y1=\"0\" x2=\"71\" y2=\"25\" />\n",
       "  <line x1=\"58\" y1=\"0\" x2=\"83\" y2=\"25\" />\n",
       "  <line x1=\"70\" y1=\"0\" x2=\"95\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"107\" y2=\"25\" />\n",
       "  <line x1=\"94\" y1=\"0\" x2=\"119\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"122\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 97.0,0.0 122.96521372150383,25.965213721503837 35.96521372150384,25.965213721503837\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"122\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"37\" x2=\"122\" y2=\"37\" />\n",
       "  <line x1=\"35\" y1=\"49\" x2=\"122\" y2=\"49\" />\n",
       "  <line x1=\"35\" y1=\"61\" x2=\"122\" y2=\"61\" />\n",
       "  <line x1=\"35\" y1=\"73\" x2=\"122\" y2=\"73\" />\n",
       "  <line x1=\"35\" y1=\"85\" x2=\"122\" y2=\"85\" />\n",
       "  <line x1=\"35\" y1=\"97\" x2=\"122\" y2=\"97\" />\n",
       "  <line x1=\"35\" y1=\"109\" x2=\"122\" y2=\"109\" />\n",
       "  <line x1=\"35\" y1=\"121\" x2=\"122\" y2=\"121\" />\n",
       "  <line x1=\"35\" y1=\"133\" x2=\"122\" y2=\"133\" />\n",
       "  <line x1=\"35\" y1=\"145\" x2=\"122\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"47\" y1=\"25\" x2=\"47\" y2=\"145\" />\n",
       "  <line x1=\"59\" y1=\"25\" x2=\"59\" y2=\"145\" />\n",
       "  <line x1=\"71\" y1=\"25\" x2=\"71\" y2=\"145\" />\n",
       "  <line x1=\"83\" y1=\"25\" x2=\"83\" y2=\"145\" />\n",
       "  <line x1=\"95\" y1=\"25\" x2=\"95\" y2=\"145\" />\n",
       "  <line x1=\"107\" y1=\"25\" x2=\"107\" y2=\"145\" />\n",
       "  <line x1=\"119\" y1=\"25\" x2=\"119\" y2=\"145\" />\n",
       "  <line x1=\"122\" y1=\"25\" x2=\"122\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"35.96521372150384,25.965213721503837 122.96521372150383,25.965213721503837 122.96521372150383,145.96521372150383 35.96521372150384,145.96521372150383\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"79.465214\" y=\"165.965214\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >928</text>\n",
       "  <text x=\"142.965214\" y=\"85.965214\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,142.965214,85.965214)\">1280</text>\n",
       "  <text x=\"12.982607\" y=\"152.982607\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,12.982607,152.982607)\">464</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<astype, shape=(464, 1280, 928), dtype=float32, chunksize=(128, 128, 128), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zarr_dataset.lazy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b976be7-e815-46bd-91d9-4022574238ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_indices = zarr_dataset.lazy_data.shape[-3:] // np.array(prediction_chunksize)\n",
    "# output_shape = tuple(\n",
    "#     n * c - (n - 1) * o\n",
    "#     for n, c, o in zip(chunk_indices, prediction_chunksize, overlap_prediction_chunksize)\n",
    "# )\n",
    "\n",
    "# chunk_indices_grid = np.array(\n",
    "#     np.meshgrid(\n",
    "#         np.arange(chunk_indices[0]),\n",
    "#         np.arange(chunk_indices[1]),\n",
    "#         np.arange(chunk_indices[2]),\n",
    "#         indexing='ij'\n",
    "#     )\n",
    "# ).reshape(3, -1).T\n",
    "\n",
    "# print(chunk_indices, output_shape, chunk_indices_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c59703-a121-4ad1-ac99-4a8ba7b3262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_start = np.array([ix, iy, iz]) * (np.array(chunk_size) - np.array(overlap_size))\n",
    "# global_end = global_start + valid_end - valid_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805544b1-e9da-474d-906b-2589696d9e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 464, 1280, 928) (1, 1, 464, 1280, 928) (1, 1, 464, 1280, 928)\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "\n",
    "output_seg_path = f\"/scratch/intermediate_seg_{smartspim_id}.zarr\"\n",
    "output_prob_path = f\"/scratch/intermediate_prob_{smartspim_id}.zarr\"\n",
    "output_data_path = f\"/scratch/data_{smartspim_id}.zarr\"\n",
    "\n",
    "output_intermediate_seg = zarr.open(\n",
    "    output_seg_path,\n",
    "    \"w\",\n",
    "    shape=(\n",
    "        1,\n",
    "        1,\n",
    "    )\n",
    "    + zarr_dataset.lazy_data.shape[-3:],\n",
    "    chunks=(\n",
    "        1,\n",
    "        1,\n",
    "    )\n",
    "    + (128, 128, 128),\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "output_intermediate_prob = zarr.open(\n",
    "    output_prob_path,\n",
    "    \"w\",\n",
    "    shape=(\n",
    "        1,\n",
    "        1,\n",
    "    )\n",
    "    + zarr_dataset.lazy_data.shape[-3:],\n",
    "    chunks=(\n",
    "        1,\n",
    "        1,\n",
    "    )\n",
    "    + (128, 128, 128),\n",
    "    dtype=np.float16,\n",
    ")\n",
    "\n",
    "output_raw_data = zarr.open(\n",
    "    output_data_path,\n",
    "    \"w\",\n",
    "    shape=(\n",
    "        1,\n",
    "        1,\n",
    "    )\n",
    "    + zarr_dataset.lazy_data.shape[-3:],\n",
    "    chunks=(\n",
    "        1,\n",
    "        1,\n",
    "    )\n",
    "    + (128, 128, 128),\n",
    "    dtype=np.uint16,\n",
    ")\n",
    "\n",
    "shape = zarr_dataset.lazy_data.shape[-3:]\n",
    "print(output_intermediate_seg.shape, output_intermediate_prob.shape, output_raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba146264-2e22-4232-9e43-babb69380df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neuratt(\n",
       "  (model): SwinUNETR(\n",
       "    (swinViT): SwinTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(1, 12, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (layers1): ModuleList(\n",
       "        (0): BasicLayer(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=12, out_features=36, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLPBlock(\n",
       "                (linear1): Linear(in_features=12, out_features=48, bias=True)\n",
       "                (linear2): Linear(in_features=48, out_features=12, bias=True)\n",
       "                (fn): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchMerging(\n",
       "            (reduction): Linear(in_features=48, out_features=24, bias=False)\n",
       "            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers2): ModuleList(\n",
       "        (0): BasicLayer(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=24, out_features=72, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLPBlock(\n",
       "                (linear1): Linear(in_features=24, out_features=96, bias=True)\n",
       "                (linear2): Linear(in_features=96, out_features=24, bias=True)\n",
       "                (fn): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchMerging(\n",
       "            (reduction): Linear(in_features=96, out_features=48, bias=False)\n",
       "            (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers3): ModuleList(\n",
       "        (0): BasicLayer(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLPBlock(\n",
       "                (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
       "                (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
       "                (fn): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchMerging(\n",
       "            (reduction): Linear(in_features=192, out_features=96, bias=False)\n",
       "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers4): ModuleList(\n",
       "        (0): BasicLayer(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLPBlock(\n",
       "                (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
       "                (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
       "                (fn): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchMerging(\n",
       "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder1): UnetrBasicBlock(\n",
       "      (layer): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(1, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (conv3): Convolution(\n",
       "          (conv): Conv2d(1, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (norm3): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (encoder2): UnetrBasicBlock(\n",
       "      (layer): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (encoder3): UnetrBasicBlock(\n",
       "      (layer): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (encoder4): UnetrBasicBlock(\n",
       "      (layer): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (encoder10): UnetrBasicBlock(\n",
       "      (layer): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (decoder5): UnetrUpBlock(\n",
       "      (transp_conv): Convolution(\n",
       "        (conv): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (conv_block): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (conv3): Convolution(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (decoder4): UnetrUpBlock(\n",
       "      (transp_conv): Convolution(\n",
       "        (conv): ConvTranspose2d(96, 48, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (conv_block): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (conv3): Convolution(\n",
       "          (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (norm3): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (decoder3): UnetrUpBlock(\n",
       "      (transp_conv): Convolution(\n",
       "        (conv): ConvTranspose2d(48, 24, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (conv_block): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (conv3): Convolution(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (norm3): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (decoder2): UnetrUpBlock(\n",
       "      (transp_conv): Convolution(\n",
       "        (conv): ConvTranspose2d(24, 12, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (conv_block): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (conv3): Convolution(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (norm3): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (decoder1): UnetrUpBlock(\n",
       "      (transp_conv): Convolution(\n",
       "        (conv): ConvTranspose2d(12, 12, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (conv_block): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (conv3): Convolution(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (norm3): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (out): UnetOutBlock(\n",
       "      (conv): Convolution(\n",
       "        (conv): Conv2d(12, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_data): NormalizeAndRescaleWrapper(\n",
       "    (normalize): Normalize(p=1.0, p_batch=1.0, same_on_batch=True, mean=tensor([0.]), std=tensor([1.]))\n",
       "  )\n",
       "  (loss_fn): BCEWithLogitsLoss()\n",
       "  (dice_score_metric): BinaryF1Score()\n",
       "  (jaccard_index_metric): BinaryJaccardIndex()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234453d7-6297-4e21-9ebb-8bcae8148875",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db92c47-a6b2-4b10-bd28-9086bb0aed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cuda_device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "148828b0-4686-4ddf-a40e-2d2d4a23328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_fill_holes\n",
    "from scipy.ndimage import binary_closing\n",
    "from skimage.morphology import ball\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "def post_process_mask(mask, threshold=0.5, min_size=100):\n",
    "    mask = binary_fill_holes(mask)\n",
    "    mask = remove_small_objects(mask, min_size=min_size)\n",
    "    \n",
    "    # structuring_element = ball(radius=5)\n",
    "    mask = binary_closing(mask)#, structure=structuring_element)\n",
    "    \n",
    "    mask = gaussian_filter(mask.astype(float), sigma=1)\n",
    "\n",
    "    mask = mask > threshold\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77df998c-a18b-459d-ad39-dd18cd08f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:  (1280, 928)\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(0, 4, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(4, 8, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(8, 12, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(12, 16, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(16, 20, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(20, 24, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(24, 28, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(28, 32, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(32, 36, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(36, 40, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(40, 44, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(44, 48, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(48, 52, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(52, 56, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999998807907104\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(56, 60, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999998807907104\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999997615814209\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(60, 64, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999997615814209\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999994039535522\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(64, 68, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999994039535522\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999982118606567\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(68, 72, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999982118606567\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999984502792358\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(72, 76, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999984502792358\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.999997615814209\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(76, 80, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.999997615814209\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999957084655762\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(80, 84, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999957084655762\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999948740005493\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(84, 88, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999948740005493\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999938011169434\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(88, 92, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999938011169434\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999949932098389\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(92, 96, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999949932098389\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999961853027344\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(96, 100, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999961853027344\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.999994158744812\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(100, 104, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.999994158744812\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999938011169434\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(104, 108, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999938011169434\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.999995231628418\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(108, 112, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.999995231628418\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999949932098389\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(112, 116, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999949932098389\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999932050704956\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(116, 120, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999932050704956\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.999991774559021\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(120, 124, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.999991774559021\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999852180480957\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(124, 128, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999852180480957\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999827146530151\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(128, 132, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999827146530151\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999783039093018\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(132, 136, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999783039093018\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999841451644897\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(136, 140, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999841451644897\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999818801879883\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(140, 144, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999818801879883\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999806880950928\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(144, 148, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999806880950928\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999796152114868\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(148, 152, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999796152114868\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999808073043823\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(152, 156, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999808073043823\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.99998939037323\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(156, 160, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.99998939037323\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999823570251465\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(160, 164, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999823570251465\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999760389328003\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(164, 168, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999760389328003\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999724626541138\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(168, 172, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999724626541138\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999734163284302\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(172, 176, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999734163284302\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999696016311646\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(176, 180, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999696016311646\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999855756759644\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(180, 184, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999855756759644\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999774694442749\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(184, 188, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999774694442749\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999570846557617\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(188, 192, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999570846557617\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999552965164185\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(192, 196, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999552965164185\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999502897262573\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(196, 200, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999502897262573\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999436140060425\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(200, 204, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999436140060425\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999406337738037\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(204, 208, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999406337738037\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999434947967529\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(208, 212, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999434947967529\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.999950647354126\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(212, 216, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.999950647354126\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999287128448486\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(216, 220, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999287128448486\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999279975891113\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(220, 224, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999279975891113\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.999924898147583\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(224, 228, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.999924898147583\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999175071716309\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(228, 232, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999175071716309\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.999927282333374\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(232, 236, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.999927282333374\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.999934196472168\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(236, 240, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.999934196472168\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999436140060425\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(240, 244, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999436140060425\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999508857727051\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(244, 248, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999508857727051\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999544620513916\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(248, 252, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999544620513916\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999589920043945\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(252, 256, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999589920043945\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999617338180542\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(256, 260, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999617338180542\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999755620956421\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(260, 264, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999755620956421\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999721050262451\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(264, 268, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999721050262451\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999946355819702\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(268, 272, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999946355819702\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999788999557495\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(272, 276, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999788999557495\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.999987006187439\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(276, 280, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.999987006187439\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999842643737793\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(280, 284, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999842643737793\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999817609786987\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(284, 288, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999817609786987\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999837875366211\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(288, 292, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999837875366211\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999901056289673\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(292, 296, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999901056289673\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999874830245972\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(296, 300, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999874830245972\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999912977218628\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(300, 304, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999912977218628\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999854564666748\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(304, 308, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999854564666748\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999825954437256\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(308, 312, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999825954437256\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999878406524658\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(312, 316, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999878406524658\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999946355819702\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(316, 320, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999946355819702\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999895095825195\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(320, 324, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999895095825195\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999920129776001\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(324, 328, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999920129776001\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999908208847046\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(328, 332, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999908208847046\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.999993085861206\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(332, 336, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.999993085861206\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999953508377075\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(336, 340, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999953508377075\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999966621398926\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(340, 344, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999966621398926\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999967813491821\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(344, 348, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999967813491821\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999970197677612\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(348, 352, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999970197677612\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999985694885254\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(352, 356, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999985694885254\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999972581863403\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(356, 360, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999972581863403\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999985694885254\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(360, 364, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999985694885254\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 0.9999996423721313\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(364, 368, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 0.9999996423721313\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(368, 372, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(372, 376, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(376, 380, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(380, 384, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(384, 388, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(388, 392, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(392, 396, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(396, 400, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(400, 404, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(404, 408, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(408, 412, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(412, 416, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(416, 420, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(420, 424, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(424, 428, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(428, 432, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(432, 436, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(436, 440, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(440, 444, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(444, 448, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(448, 452, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(452, 456, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(456, 460, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "Slice orig: (4, 1280, 928)\n",
      "Slice data: torch.Size([4, 1, 1024, 1024])\n",
      "Block torch.Size([4, 1, 1024, 1024]) - Max mask: 1.0\n",
      "Tensor shape: torch.Size([1, 4, 1280, 928]) - Pred mask -> (4, 1024, 1024) - unpadded_global_slice: (slice(0, 1, None), slice(0, 1, None), slice(460, 464, None), slice(0, 1280, None), slice(0, 928, None)) Max mask: 1.0\n",
      "CPU times: user 3min 18s, sys: 1min 13s, total: 4min 31s\n",
      "Wall time: 18min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# import cupy as cp\n",
    "import torchvision.transforms.functional as TF\n",
    "import cv2\n",
    "from skimage.transform import resize as ski_resize\n",
    "\n",
    "image_height = 1024\n",
    "image_width = 1024\n",
    "orig_shape = zarr_dataset.lazy_data.shape[-2:]\n",
    "THRES = 0.7\n",
    "print(\"Original shape: \", orig_shape)\n",
    "\n",
    "for i, sample in enumerate(zarr_data_loader):\n",
    "    # Load batch as a NumPy array (but keep it on GPU when possible)\n",
    "    slice_data_orig = np.squeeze(sample.batch_tensor.numpy())\n",
    "\n",
    "    # Preallocate array in GPU memory for batch resizing\n",
    "    slice_data = torch.zeros(\n",
    "        (slice_data_orig.shape[0], 1, image_height, image_width), device=cuda_device, dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    print(\"Slice orig:\", slice_data_orig.shape)\n",
    "\n",
    "    # **GPU-Accelerated Resizing**\n",
    "    for i in range(slice_data_orig.shape[0]):\n",
    "        slice_img = torch.tensor(slice_data_orig[i], device=cuda_device).unsqueeze(0).unsqueeze(0)\n",
    "        slice_data[i] = F.interpolate(slice_img, size=(image_height, image_width), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    print(\"Slice data:\", slice_data.shape)\n",
    "\n",
    "    # **Model Prediction**\n",
    "    pred_mask, prob_mask = segmentation_model.predict(batch=slice_data, threshold=THRES)\n",
    "\n",
    "    print(f\"Block {slice_data.shape} - Max mask: {prob_mask.max()}\")\n",
    "\n",
    "    # Move to CPU and convert to NumPy in one step (avoiding unnecessary copies)\n",
    "    pred_mask = pred_mask.squeeze().detach().cpu().numpy()\n",
    "    prob_mask = prob_mask.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # **Preallocate Resized Masks on CPU**\n",
    "    pred_mask_resampled = np.zeros((pred_mask.shape[0],) + orig_shape, dtype=np.uint8)\n",
    "    prob_mask_resampled = np.zeros((prob_mask.shape[0],) + orig_shape, dtype=np.float32)\n",
    "\n",
    "    # **Resize with OpenCV (Faster than skimage)**\n",
    "    for i in range(pred_mask.shape[0]):\n",
    "        pred_mask_resampled[i] = cv2.resize(pred_mask[i], orig_shape[::-1], interpolation=cv2.INTER_NEAREST)\n",
    "        prob_mask_resampled[i] = cv2.resize(prob_mask[i], orig_shape[::-1], interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # **Compute Global Positions Efficiently**\n",
    "    (\n",
    "        global_coord_pos,\n",
    "        global_coord_positions_start,\n",
    "        global_coord_positions_end,\n",
    "    ) = recover_global_position(\n",
    "        super_chunk_slice=sample.batch_super_chunk[0],\n",
    "        internal_slices=sample.batch_internal_slice,\n",
    "    )\n",
    "\n",
    "    unpadded_global_slice, unpadded_local_slice = unpad_global_coords(\n",
    "        global_coord_pos=global_coord_pos[-3:],\n",
    "        block_shape=slice_data.shape[-3:],\n",
    "        overlap_prediction_chunksize=overlap_prediction_chunksize[-3:],\n",
    "        dataset_shape=zarr_dataset.lazy_data.shape[-3:],\n",
    "    )\n",
    "\n",
    "    # **Move Tensors Off GPU to Free Memory**\n",
    "    del slice_data\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    unpadded_global_slice = (slice(0, 1), slice(0, 1)) + unpadded_global_slice\n",
    "\n",
    "    print(\n",
    "        f\"Tensor shape: {sample.batch_tensor.shape} - Pred mask -> {pred_mask.shape} - unpadded_global_slice: {unpadded_global_slice} Max mask: {prob_mask.max()}\"\n",
    "    )\n",
    "    # **Store Output Efficiently**\n",
    "    output_intermediate_seg[unpadded_global_slice] = pred_mask_resampled[None, None, ...]#[unpadded_global_slice]\n",
    "    output_raw_data[unpadded_global_slice] = slice_data_orig[None, None, ...]#[unpadded_global_slice]\n",
    "    output_intermediate_prob[unpadded_global_slice] = prob_mask_resampled[None, None, ...]#[unpadded_global_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5e4ffdd-7a95-4364-9387-e64b0c8e133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 468.98 MiB </td>\n",
       "                        <td> 2.00 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1, 480, 1104, 928) </td>\n",
       "                        <td> (1, 1, 128, 128, 128) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 288 chunks in 2 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint8 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"371\" height=\"200\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1</text>\n",
       "  <text x=\"45.412617\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,45.412617,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"125\" y2=\"30\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"95\" y1=\"13\" x2=\"125\" y2=\"44\" />\n",
       "  <line x1=\"95\" y1=\"27\" x2=\"125\" y2=\"58\" />\n",
       "  <line x1=\"95\" y1=\"41\" x2=\"125\" y2=\"72\" />\n",
       "  <line x1=\"95\" y1=\"55\" x2=\"125\" y2=\"86\" />\n",
       "  <line x1=\"95\" y1=\"69\" x2=\"125\" y2=\"100\" />\n",
       "  <line x1=\"95\" y1=\"83\" x2=\"125\" y2=\"114\" />\n",
       "  <line x1=\"95\" y1=\"97\" x2=\"125\" y2=\"128\" />\n",
       "  <line x1=\"95\" y1=\"111\" x2=\"125\" y2=\"141\" />\n",
       "  <line x1=\"95\" y1=\"120\" x2=\"125\" y2=\"150\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"95\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"103\" y1=\"8\" x2=\"103\" y2=\"128\" />\n",
       "  <line x1=\"111\" y1=\"16\" x2=\"111\" y2=\"136\" />\n",
       "  <line x1=\"119\" y1=\"24\" x2=\"119\" y2=\"144\" />\n",
       "  <line x1=\"125\" y1=\"30\" x2=\"125\" y2=\"150\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 125.69053708439898,30.69053708439898 125.69053708439898,150.69053708439898 95.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"195\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"103\" y1=\"8\" x2=\"204\" y2=\"8\" />\n",
       "  <line x1=\"111\" y1=\"16\" x2=\"212\" y2=\"16\" />\n",
       "  <line x1=\"119\" y1=\"24\" x2=\"220\" y2=\"24\" />\n",
       "  <line x1=\"125\" y1=\"30\" x2=\"226\" y2=\"30\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"125\" y2=\"30\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"108\" y1=\"0\" x2=\"139\" y2=\"30\" />\n",
       "  <line x1=\"122\" y1=\"0\" x2=\"153\" y2=\"30\" />\n",
       "  <line x1=\"136\" y1=\"0\" x2=\"167\" y2=\"30\" />\n",
       "  <line x1=\"150\" y1=\"0\" x2=\"181\" y2=\"30\" />\n",
       "  <line x1=\"164\" y1=\"0\" x2=\"195\" y2=\"30\" />\n",
       "  <line x1=\"178\" y1=\"0\" x2=\"209\" y2=\"30\" />\n",
       "  <line x1=\"192\" y1=\"0\" x2=\"223\" y2=\"30\" />\n",
       "  <line x1=\"195\" y1=\"0\" x2=\"226\" y2=\"30\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 195.8695652173913,0.0 226.5601023017903,30.69053708439898 125.69053708439898,30.69053708439898\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"125\" y1=\"30\" x2=\"226\" y2=\"30\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"125\" y1=\"44\" x2=\"226\" y2=\"44\" />\n",
       "  <line x1=\"125\" y1=\"58\" x2=\"226\" y2=\"58\" />\n",
       "  <line x1=\"125\" y1=\"72\" x2=\"226\" y2=\"72\" />\n",
       "  <line x1=\"125\" y1=\"86\" x2=\"226\" y2=\"86\" />\n",
       "  <line x1=\"125\" y1=\"100\" x2=\"226\" y2=\"100\" />\n",
       "  <line x1=\"125\" y1=\"114\" x2=\"226\" y2=\"114\" />\n",
       "  <line x1=\"125\" y1=\"128\" x2=\"226\" y2=\"128\" />\n",
       "  <line x1=\"125\" y1=\"141\" x2=\"226\" y2=\"141\" />\n",
       "  <line x1=\"125\" y1=\"150\" x2=\"226\" y2=\"150\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"125\" y1=\"30\" x2=\"125\" y2=\"150\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"139\" y1=\"30\" x2=\"139\" y2=\"150\" />\n",
       "  <line x1=\"153\" y1=\"30\" x2=\"153\" y2=\"150\" />\n",
       "  <line x1=\"167\" y1=\"30\" x2=\"167\" y2=\"150\" />\n",
       "  <line x1=\"181\" y1=\"30\" x2=\"181\" y2=\"150\" />\n",
       "  <line x1=\"195\" y1=\"30\" x2=\"195\" y2=\"150\" />\n",
       "  <line x1=\"209\" y1=\"30\" x2=\"209\" y2=\"150\" />\n",
       "  <line x1=\"223\" y1=\"30\" x2=\"223\" y2=\"150\" />\n",
       "  <line x1=\"226\" y1=\"30\" x2=\"226\" y2=\"150\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"125.69053708439898,30.69053708439898 226.56010230179027,30.69053708439898 226.56010230179027,150.69053708439898 125.69053708439898,150.69053708439898\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"176.125320\" y=\"170.690537\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >928</text>\n",
       "  <text x=\"246.560102\" y=\"90.690537\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,246.560102,90.690537)\">1104</text>\n",
       "  <text x=\"100.345269\" y=\"155.345269\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,100.345269,155.345269)\">480</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(1, 1, 480, 1104, 928), dtype=uint8, chunksize=(1, 1, 128, 128, 128), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.array as da\n",
    "lazy_seg = da.from_zarr(output_seg_path)\n",
    "lazy_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab34631d-de74-4496-b317-cb9be425b5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_seg.compute().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b64ca62-9400-43cc-aea3-f2dd2dffbe66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(lazy_seg[0, 0, 200, ...], vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca98266-3c79-47f3-87a1-aec8c6e0fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, sample in enumerate(zarr_data_loader):\n",
    "#     block = sample.batch_tensor[None, ...].to(cuda_device)\n",
    "#     pred_mask, prob_mask = segmentation_model.predict(\n",
    "#         batch=block,\n",
    "#         threshold=0.5,\n",
    "#     )\n",
    "\n",
    "#     (\n",
    "#         global_coord_pos,\n",
    "#         global_coord_positions_start,\n",
    "#         global_coord_positions_end,\n",
    "#     ) = recover_global_position(\n",
    "#         super_chunk_slice=sample.batch_super_chunk[0],\n",
    "#         internal_slices=sample.batch_internal_slice,\n",
    "#     )\n",
    "\n",
    "#     global_coord_positions_start = np.array(global_coord_positions_start[0])\n",
    "#     global_coord_positions_end = np.array(global_coord_positions_end[0])\n",
    "\n",
    "#     # start_condition = np.where(\n",
    "#     #     (global_coord_positions_start > 0) &\n",
    "#     #     (global_coord_positions_start != shape)\n",
    "#     # )[0]\n",
    "\n",
    "#     # global_coord_positions_start[start_condition] += (axis_pad * (2**len(start_condition)))\n",
    "\n",
    "#     # end_condition = np.where(\n",
    "#     #     (global_coord_positions_end > 0) &\n",
    "#     #     (global_coord_positions_end != shape)\n",
    "#     # )[0]\n",
    "\n",
    "#     # global_coord_positions_end[start_condition] += (axis_pad * (2**len(start_condition)))\n",
    "\n",
    "#     start_condition = np.where(\n",
    "#         (global_coord_positions_start == 0)\n",
    "#     )[0]\n",
    "\n",
    "#     if len(start_condition) == len(shape):\n",
    "#         new_global_stop = global_coord_positions_end\n",
    "\n",
    "#     else:\n",
    "        \n",
    "        \n",
    "\n",
    "#     new_global_coords = []\n",
    "#     for i in range(len(global_coord_positions_start)):\n",
    "#         new_global_coords.append(\n",
    "#             slice(\n",
    "#                 global_coord_positions_start[i],\n",
    "#                 global_coord_positions_end[i],\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     new_global_coords = (slice(0, 1), slice(0, 1), ) + tuple(new_global_coords)\n",
    "\n",
    "#     # output_intermediate_seg[new_global_coords] = pred_mask\n",
    "    \n",
    "#     # print(global_coord_positions_start, global_coord_positions_end, global_coord_pos, new_global_coords, shape)\n",
    "\n",
    "#     # Pinned?: {sample.batch_tensor.is_pinned()} - dtype: {sample.batch_tensor.dtype}\n",
    "    \n",
    "#     print(\n",
    "#         f\"Tensor shape: {sample.batch_tensor.shape} - Pred mask -> {pred_mask.shape} Global coords: {global_coord_pos} - new global {new_global_coords}\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f704c02f-ac2c-4628-8d15-5a3117e5d768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120, 120])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = np.array([120, 120, 120])\n",
    "shape = np.array([512, 1408, 1024])\n",
    "\n",
    "condition = np.where( (position > 0) & (position != shape) )[0]\n",
    "position[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c8fb3-340c-40b8-937f-1300c402d86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60958caf-df1d-491b-84a6-cc80cc6b4e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
